"""
Code Migrator Module (code_migrator.py)

Core execution engine for PySpark to Snowpark code migration using LLM assistance.
Implements a "triage doctor" approach for intelligent migration decision-making.
"""

from typing import List, Dict, Any
from services.llm_service import CortexLLMService
from services.knowledge_service import KnowledgeService


class MigrationError(Exception):
    """用于迁移过程中发生的特定错误。"""
    pass


class CodeMigrator:
    """Core code migration engine that transforms PySpark functions to Snowpark equivalents."""

    def __init__(self, llm_service: CortexLLMService):
        """Initialize the code migrator instance."""
        self.llm_service = llm_service

    def migrate_function(
            self,
            source_code: str,
            function_analysis: dict,
            knowledge_service: KnowledgeService
    ) -> str:
        """
        Migrate a PySpark function to Snowpark equivalent using triage approach.

        Args:
            source_code: Function code with inline migration guidance
            function_analysis: Analysis data containing dependencies info
            knowledge_service: Knowledge service instance

        Returns:
            str: Migrated Snowpark function code or manual intervention stub
        """
        try:
            # Extract dependencies from analysis
            dependencies = function_analysis['dependencies']['external_packages']

            # Check migration feasibility (triage)
            decision = self._check_migration_feasibility(dependencies)

            # Execute based on triage decision
            if decision['action'] == 'ABORT_AND_FLAG':
                return self._generate_manual_intervention_stub(
                    decision['details'][0], source_code
                )
            elif decision['action'] == 'PROCEED_AND_MIGRATE':
                return self._run_llm_migration(source_code, function_analysis, knowledge_service)
            elif decision['action'] == 'PROCEED_AND_ANNOTATE':
                migrated_code = self._run_llm_migration(source_code, function_analysis, knowledge_service)
                return self._add_annotations_for_custom_modules(migrated_code, decision['details'])

        except Exception as e:
            raise MigrationError(f"Failed to migrate function: {str(e)}") from e

    def _check_migration_feasibility(self, dependencies: List[str]) -> dict:
        """
        Check migration feasibility using triage logic.

        Args:
            dependencies: List of import statements from function analysis

        Returns:
            dict: Decision object with 'action' and 'details' keys
        """
        # Define fatal (non-migratable) dependencies
        fatal_keywords = ['config.spark_config', 'requests', 'boto3', 'os.path.exists']

        # Define custom module patterns
        custom_module_keywords = ['utils.', 'libs.', 'common.']

        action = 'PROCEED_AND_MIGRATE'
        custom_modules_found = []

        for import_statement in dependencies:
            # Check for fatal dependencies first
            if any(keyword in import_statement for keyword in fatal_keywords):
                return {'action': 'ABORT_AND_FLAG', 'details': [import_statement]}

            # Check for custom modules
            if any(keyword in import_statement for keyword in custom_module_keywords):
                custom_modules_found.append(import_statement)

        # Return decision based on findings
        if custom_modules_found:
            return {'action': 'PROCEED_AND_ANNOTATE', 'details': custom_modules_found}

        return {'action': 'PROCEED_AND_MIGRATE', 'details': []}

    def _run_llm_migration(
            self,
            source_code: str,
            function_analysis: dict,
            knowledge_service: KnowledgeService
    ) -> str:
        """
        Execute standard LLM-based code migration.

        Args:
            source_code: Function code to migrate
            function_analysis: Analysis data from code_analyzer
            knowledge_service: Knowledge service instance

        Returns:
            str: LLM-generated migrated code
        """
        # Get suggested patterns and recipes
        suggested_patterns = function_analysis.get('suggested_patterns', [])
        recipes = knowledge_service.get_recipes_from_suggested_patterns(suggested_patterns)

        # Build migration prompt and get LLM response
        prompt = self._build_migration_prompt(source_code, recipes)
        response = self.llm_service.get_text_completion(prompt)

        return response.strip()

    def _add_annotations_for_custom_modules(
            self,
            migrated_code: str,
            custom_imports: List[str]
    ) -> str:
        """
        Add warning annotations for custom module imports.

        Args:
            migrated_code: Code generated by LLM migration
            custom_imports: List of custom import statements to annotate

        Returns:
            str: Code with warning annotations added
        """
        WARNING_TEMPLATE = """# MIGRATION TOOL WARNING: Manual check required for the following custom import.
# Please ensure the module '{module_name}' is available in the Snowpark environment
# and its internal logic is compatible."""

        result_code = migrated_code

        for import_statement in custom_imports:
            # Extract module name from import statement
            if 'from ' in import_statement:
                module_name = import_statement.split('from ')[1].split(' import')[0].strip()
            elif 'import ' in import_statement:
                module_name = import_statement.split('import ')[1].split(' as')[0].strip()
            else:
                module_name = 'unknown'

            # Replace import with annotated version
            warning = WARNING_TEMPLATE.format(module_name=module_name)
            annotated_import = f"{warning}\n{import_statement}"
            result_code = result_code.replace(import_statement, annotated_import)

        return result_code

    def _generate_manual_intervention_stub(self, reason: str, source_code: str) -> str:
        """
        Generate manual intervention stub for non-migratable functions.

        Args:
            reason: Reason for migration abort
            source_code: Original PySpark function code

        Returns:
            str: Formatted warning stub with original code
        """
        return f"""
# ##############################################################################
# ### MIGRATION SKIPPED: MANUAL INTERVENTION REQUIRED                          ###
# ##############################################################################
#
# REASON: {reason}
#
# The following PySpark function could not be automatically migrated.
# Please review the code and manually convert it to its Snowpark equivalent.
#
# --- ORIGINAL PYSPARK CODE ---
#
'''
{source_code}
'''
"""

    def _build_migration_prompt(self, function_code: str, recipes: list) -> str:
        """Build the complete migration prompt for the LLM."""
        formatted_recipes = self._format_recipes(recipes)

        return f"""You are an expert software engineer specializing in migrating Python data processing code from libraries like Pandas and PySpark to Snowpark. Your task is to perform a precise and functionally equivalent migration.

**Critical Task Briefing:**
1.  **Analyze Source**: First, analyze the source function to determine if it primarily uses Pandas or PySpark.
2.  **Select Knowledge**: Based on your analysis, you MUST use the corresponding set of reference examples provided below.
3.  **Follow Guidance**: The function contains CRITICAL inline comments added by a previous analysis step. These comments provide essential context about the source library's patterns (e.g., Pandas-specific issues like `.apply` or PySpark-specific issues like UDFs) and are your most important guide.
4.  **Migrate**: Translate the function to Snowpark, following all rules.

---[REFERENCE EXAMPLES]---
{formatted_recipes}
---[END REFERENCE EXAMPLES]---

---[FUNCTION TO MIGRATE]---
```python
{function_code}
```
---[END FUNCTION]---

MIGRATION RULES:
1. Preserve original function signature (name and parameters)
2. Follow ALL inline migration guidance comments. These are not optional.
3. After applying the guidance from a comment, remove the guidance comment itself from the final code. Keep the original docstring.
4. Translate source library APIs (Pandas, PySpark) to their Snowpark equivalents using the correct set of reference examples.
5. Pure Python logic (loops, conditions, variable assignments) should be maintained.
6. If you encounter an API or pattern that you cannot confidently migrate, insert a comment: # TODO: [MANUAL MIGRATION REQUIRED] - Reason: brief explanation.
7. Your output MUST ONLY be the final, migrated Python code for the function. Do not include any explanations or markdown formatting.

Begin migration now."""

    def _format_recipes(self, recipes: list) -> str:
        """Format recipes into readable text blocks for the prompt."""
        if not recipes:
            return "No specific recipes available."

        formatted_blocks = []
        for recipe in recipes:
            recipe_id = recipe.get('id', 'Unknown Pattern')
            description = recipe.get('description', 'No description')
            snowpark_code = recipe.get('snowpark_code', 'No implementation')

            formatted_blocks.append(f"""# Pattern: {recipe_id}
# Description: {description}
# Snowpark Implementation:
{snowpark_code}""")

        return '\n\n'.join(formatted_blocks)