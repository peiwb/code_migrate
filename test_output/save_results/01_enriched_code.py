def save_results(df: DataFrame, output_path: str, format_type: str = "parquet") -> None:
    """Save processed data to specified location.
    
    This function saves a PySpark DataFrame to disk in various formats with optimization
    for single-file output. The coalesce(1) operation consolidates all partitions into
    a single file to avoid multiple part files, which is useful for downstream systems
    that expect single files but may impact performance for large datasets.
    
    Args:
        df (DataFrame): The PySpark DataFrame to save. Must be a valid DataFrame object.
        output_path (str): The target directory path where the file will be saved.
            For distributed file systems (HDFS, S3), this should be a full URI.
            The actual filename will be auto-generated by Spark.
        format_type (str, optional): The output file format. Supported values are
            "parquet", "csv", and "json". Case-insensitive. Defaults to "parquet".
            
    Returns:
        None: This function performs a side effect (file I/O) and returns nothing.
        
    Raises:
        ValueError: If format_type is not one of the supported formats.
        
    Note:
        - Uses overwrite mode, which will delete existing data at the output path
        - coalesce(1) forces single partition output but may create performance bottlenecks
        - CSV format includes headers by default for better interoperability
        - For migration: Consider partition handling and file size implications on target platform
    """
    # Coalesce to single partition for consolidated output - consider performance vs file count trade-off
    # Overwrite mode ensures idempotent behavior but destroys existing data
    writer = df.coalesce(1).write.mode("overwrite")

    # Format selection with case-insensitive matching for user convenience
    if format_type.lower() == "parquet":
        # Parquet: columnar format, best for analytics workloads, preserves schema and types
        writer.parquet(output_path)
    elif format_type.lower() == "csv":
        # CSV: include headers for self-describing files, compatible with most tools
        writer.option("header", "true").csv(output_path)
    elif format_type.lower() == "json":
        # JSON: one JSON object per line (JSONL format), preserves nested structures
        writer.json(output_path)
    else:
        # Explicit error for unsupported formats to aid debugging
        raise ValueError(f"Unsupported format: {format_type}")